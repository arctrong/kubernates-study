<!DOCTYPE html>
<html>
<head><title>Theory</title>
<meta charset="utf-8">
<link rel="shortcut icon" type="image/png" href="pict/favicon.png"/>
<link rel="stylesheet" type="text/css" href="layout/styles.css"/>
<link rel="stylesheet" type="text/css" href="layout/layout.css"/>

<style>
.headerNavArrows {position: relative; top: 3px;}
</style>
</head>
<body>

<div class="header"><b style="margin-right:7px;"><span styles="">K8s</span></b><a class="header_item" href="about.html">About</a><a class="header_item" href="index_page.html">Index</a>

<a href="about.html" title="Previous: About the course"><img class="headerNavArrows" src="pict/previous_page_h18px.png"/></a>

<a href="installation.html" title="Next: Working environment installation"><img class="headerNavArrows" src="pict/next_page_h18px.png"/></a>


<span class="headerTitle">Theory</span>
</div>

<div class="sidebar">
    <table class="sidebarAligner">
        <tr><td valign="top">
            <div class="sidebar_item "><a href="about.html">About the course</a></div><div class="sidebar_item selected"><a href="index.html">Theory</a></div><div class="sidebar_item "><a href="installation.html">Working environment installation</a></div><div class="sidebar_item "><a href="kubectl_commands.html">Main Kubectl commands</a></div><div class="sidebar_item "><a href="yaml_config_file.html">YAML Configuration file</a></div><div class="sidebar_item "><a href="demo_project.html">Complete demo project</a></div><div class="sidebar_item "><a href="namespaces.html">Namespaces</a></div><div class="sidebar_item "><a href="ingress.html">Ingresses</a></div><div class="sidebar_item "><a href="helm.html">Helm Package Manager</a></div><div class="sidebar_item "><a href="volumes.html">Persisting Data with Volumes</a></div><div class="sidebar_item "><a href="stateful_sets.html">StatefulSets</a></div><div class="sidebar_item "><a href="services.html">Services</a></div>
            <h3>Side steps</h3>
            <div class="sidebar_item "><a href="external_access.html">Access external Services from outside the Minicube cluster</a></div>
        </td></tr>
        <tr><td class="bottom" valign="bottom">
            Generated by <a href="https://github.com/arctrong/md2html">md2html_py</a> 1.0.2
        </td></tr>
    </table>
</div>

<p style="font-size:44px;font-weight:bold;margin:0 0 30px 0;">Theory</p>

<!--METADATA {"title": "Theory"} -->

<div class="toc">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#orchestration-tools-features">Orchestration tools features</a></li>
<li><a href="#main-kubernetes-components">Main Kubernetes components</a><ul>
<li><a href="#nodes-and-pods">Nodes and Pods</a></li>
<li><a href="#services-and-ingresses">Services and Ingresses</a></li>
<li><a href="#configmap-and-secrets">ConfigMap and Secrets</a></li>
<li><a href="#volumes">Volumes</a></li>
<li><a href="#deployment-and-statefulset">Deployment and StatefulSet</a></li>
<li><a href="#k8s-components-summary">K8s components summary</a></li>
</ul>
</li>
<li><a href="#k8s-architecture">K8s architecture</a><ul>
<li><a href="#node-processes">Node processes</a></li>
<li><a href="#master-processes">Master processes</a></li>
<li><a href="#example-cluster-setup">Example Cluster setup</a></li>
</ul>
</li>
</ul>
</div>
<hr />
<p><em>Jun 29, 2021</em></p>
<p><a name="index_entry_index_1"></a></p>
<h1 id="introduction">Introduction</h1>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Kubernetes">Kubernetes</a>.</p>
<p>Kubernetes home page: <a href="https://kubernetes.io/">https://kubernetes.io/</a>.  <br />
Kubernetes documentation: <a href="https://kubernetes.io/docs/home/">https://kubernetes.io/docs/home/</a>.</p>
<p><strong>Kubernetes</strong> or <strong>K8s</strong> &mdash; is an open-source <strong>container-orchestration</strong> system for automating
computer application deployment, scaling, and management. It was originally designed by Google
and is now maintained by the Cloud Native Computing Foundation.</p>
<p>Kubernetes license: <a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a>.</p>
<hr />
<p><a name="index_entry_index_2"></a></p>
<h1 id="orchestration-tools-features">Orchestration tools features</h1>
<p><strong>High availability</strong> &mdash; low or no downtime.</p>
<p><strong>Scalability</strong> or high performance.</p>
<p><strong>Disaster recovery</strong> &mdash; backup and restore.</p>
<hr />
<h1 id="main-kubernetes-components">Main Kubernetes components</h1>
<p><a href="https://youtu.be/X48VuDVv0do?t=320">5:20</a></p>
<p>Documentation section: 
<a href="https://kubernetes.io/docs/concepts/overview/components/">Kubernetes Components</a>.</p>
<h2 id="nodes-and-pods">Nodes and Pods</h2>
<p><img src="pict/pods.png" style="float: left; margin: 0 25px 25px 0;" /></p>

<p><a name="index_entry_index_3"></a>
<strong>Node</strong> is a physical or virtual machine.</p>
<p><a name="index_entry_index_4"></a>
<strong>Pod</strong> &mdash; the smallest unit of K8s. Abstraction over container. K8s works not only with Docker
containers. As users we interact only with the Kubernetes layer. Each Pod has its own IP address.</p>
<p>Pods as components are <strong>ephemeral</strong>, which means they can die very easily. In this case a new Pod
with a new IP address is created that is very inconvenient. So <strong>Services</strong> come to the scene.</p>
<p style="clear: both;"></p>

<h2 id="services-and-ingresses">Services and Ingresses</h2>
<p><img src="pict/services_and_ingresses.png" style="float: left; margin: 0 25px 25px 0;" /></p>

<p><a name="index_entry_index_5"></a>
<strong>Service</strong> &mdash; an IP address that can be attached to a Pod. If the Pod dies the service and the 
IP address will stay. There may be <strong>external</strong> services that are open for external communication
and <strong>internal</strong> ones (like database services). A service is an (HTTP) IP address and a port. But 
for an end product we would want HTTPS and a domain name. In this course, there's a
<a href="services.html">separate section</a> devoted to Services.</p>
<p><a name="index_entry_index_6"></a>
<strong>Ingress</strong> accepts external requests and forwards it to the Services.</p>
<p style="clear: both;"></p>

<p><a name="index_entry_index_7"></a></p>
<h2 id="configmap-and-secrets">ConfigMap and Secrets</h2>
<p><em>Jul 1, 2021</em></p>
<p><a href="https://youtu.be/X48VuDVv0do?t=669">11:09</a></p>
<p><img alt="" src="pict/cconfigmap_01.png" /></p>
<p>We have a Pod <code>my-app</code> that communicates with a database (say <code>mongo-db</code>) and its endpoint name
changes to e.g. <code>mongo-db-1</code>. If the endpoint name is configured in the application property file
(inside the built image) then we have to do a lot of tedious work to rebuild and redeploy the
application <code>my-app</code>. Too much for such a small change.</p>
<p><strong>ConfigMap</strong> keeps parameters that the applications may access (via e.g. environment variables
or property files). <strong>Secret</strong> mechanism (not activated by default) keeps secret data (in Base64
format).</p>
<p><em>Jul 2, 2021</em></p>
<p><a name="index_entry_index_8"></a></p>
<h2 id="volumes">Volumes</h2>
<p><a href="https://youtu.be/X48VuDVv0do?t=864">14:24</a></p>
<p><img src="pict/volumes.png" style="float: left; margin: 0 25px 25px 0;" /></p>

<p>When a database Pod stops, the data is gone. <strong>Volumes</strong> are K8s components that attach physical
storage to Pods. The storage may be <em>local</em> (inside the K8s node), <em>remote</em> or <em>cloud</em> (outside
the K8s node). </p>
<p style="clear: both;"></p>

<blockquote>
<p>K8s doesn't explicitly manage the data persistence. The user or the administrator must be
responsible for the storage setup, backup, etc.</p>
</blockquote>
<p><a name="index_entry_index_9"></a></p>
<h2 id="deployment-and-statefulset">Deployment and StatefulSet</h2>
<p><a href="https://youtu.be/X48VuDVv0do?t=982">16:22</a></p>
<p><img alt="" src="pict/replicas.png" /></p>
<p>To avoid downtime we would want to use principle "replicate everything". So we create replica
Nodes in which corresponding Pods are connected to the same Services. The Services in this 
case have also a function of <strong>load balancing</strong>.</p>
<p>To create a replica of a Pod we don't create a separate instance of the Pod. Instead we define
a <em>blueprint</em> for the Pod and specify how many replicas we want to run. And this blueprint is
another K8s component called <strong>Deployment</strong>. Deployment is abstraction of <em>Pod</em>.</p>
<p>But we cannot replicate a database using a Deployment because databases are stateful. In this 
case we use another K8s component called <strong>StatefulSet</strong>. So</p>
<table>
<thead>
<tr>
<th>Deployment</th>
<th>StatefulSet</th>
</tr>
</thead>
<tbody>
<tr>
<td>for <strong>stateless</strong> applications</td>
<td>for <strong>stateful</strong> applications (or databases)</td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>Note.</strong> Deploying StatefulSets is not an easy task. So DBs are often hosted and managed
outside of a K8s cluster.</p>
</blockquote>
<h2 id="k8s-components-summary">K8s components summary</h2>
<p><img alt="" src="pict/components_summary.png" /></p>
<p>There are much more other components but these are the main ones.</p>
<hr />
<h1 id="k8s-architecture">K8s architecture</h1>
<p><a href="https://youtu.be/X48VuDVv0do?t=1349">22:29</a></p>
<p><a name="index_entry_index_10"></a>
The main topics to be discussed:</p>
<ul>
<li><strong>Master</strong> and <strong>worker</strong> (or <strong>slave</strong>) Nodes.</li>
<li>K8s <strong>Cluster</strong>.</li>
</ul>
<h2 id="node-processes">Node processes</h2>
<p><img alt="" src="pict/architecture_components_01.png" /></p>
<p>A <strong>worker service</strong> or <strong>worker Node</strong> is a Node that fulfills the user's tasks. Three
processes must be installed on <strong>every</strong> such Node:</p>
<ul>
<li><strong>Container runtime</strong> (Docker in our case);</li>
<li><a name="index_entry_index_11"></a><strong>Kubelet</strong> &mdash; the process of the K8s itself. It interacts both &mdash; 
    the container runtime
    and the Node. Kubelet starts a Pod with a container inside and assigns it resources (like
    CPU, RAM and storage);</li>
<li><strong>Kube proxy</strong> &mdash; intelligently forwards requests between Pods inside the Cluster. E.g. 
    it'll rather send request from an app Node the the database on the same Node then on the 
    other Node.</li>
</ul>
<h2 id="master-processes">Master processes</h2>
<p><a href="https://youtu.be/X48VuDVv0do?t=1586">26:26</a></p>
<p>Usually K8s Cluster consists of multiple Nodes. How to:</p>
<ul>
<li>schedule a Pod?</li>
<li>monitor?</li>
<li>reschedule/restart a Pod?</li>
<li>join a new Node?</li>
</ul>
<p>All this tasks are done by <strong>Master Nodes</strong> (or <strong>Master services</strong>).</p>
<p><img alt="" src="pict/master_processes.png" /></p>
<p>Four completely different processes run on <strong>every</strong> Master Node:</p>
<p><a id="master_node_processes"></a></p>
<ul>
<li><strong>API Server</strong> &mdash; accepts requests to the Cluster. Plays roles of:<ul>
<li>Cluster gateway;</li>
<li>gatekeeper for authentication.</li>
</ul>
</li>
<li><strong>Scheduler</strong>. When API Server is asked to run a new Pod it (after security checks) redirects
    this request to the Scheduler that intelligently decides on which Node this Pod must be run
    (depending on the available resources and the Nodes busyness). The Scheduler just decides
    where to run the Pod, the Kubelet on the Node actually does the scheduling.</li>
<li><strong>Controller Manager</strong> &mdash; detects state changes (like Pod crash) and tries to restore the
    Cluster state ASAP. It sends requests to the Scheduler and the same cycle is started 
    (including resource calculation, request to the Kubelet, etc.).</li>
<li><a name="index_entry_index_12"></a><strong>etcd</strong> (sometimes called the "cluster brain") &mdash; key-value store of
    the Cluster state. Keeps information about Nodes and Pods, the Cluster health, etc. Other
    processes use etcd when they need this information. (<strong>Note.</strong> No actual application data is
    stored in the etcd.)</li>
</ul>
<p>K8s Clusters usually have multiple Master Nodes each having their own Master processes. In this 
case:</p>
<ul>
<li>the API Services are load balanced;</li>
<li>and the etcd database is shared across all the Master Nodes.</li>
</ul>
<h2 id="example-cluster-setup">Example Cluster setup</h2>
<p><a href="https://youtu.be/X48VuDVv0do?t=1986">33:06</a></p>
<p>Let's say we will have 2 Master Nodes and 3 Worker Nodes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Master Nodes are more important but they have less load of work and consume less 
resources.</p>
</div>
<p>General algorithm of adding a new Master/Worker Node:</p>
<ul>
<li>get a new bare server;</li>
<li>install all the Master/Worker processes;</li>
<li>add it to the Cluster.</li>
</ul>
<p>&nbsp;</p>
<hr />

<p style="margin-top:0px;margin-bottom:0px;text-align:right;"><a href="about.html" 
title="Previous: About the course"><img src="pict/previous_page.png"/></a>

<a href="installation.html" title="Next: Working environment installation"><img 
src="pict/next_page.png"/></a>
</p>

<div style="height: 1000px;"><p>&nbsp;</p></div>

</body>
</html>
